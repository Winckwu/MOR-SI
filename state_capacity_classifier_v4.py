#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¿åºœé‡‡è´­åˆåŒå›½å®¶èƒ½åŠ›åˆ†ç±»å™¨ V4 - è¶…é«˜å‡†ç¡®åº¦ç‰ˆæœ¬
ç›®æ ‡ï¼šå‡†ç¡®ç‡ > 90%

æ ¸å¿ƒç­–ç•¥ï¼š
1. è¶…ç²¾ç¡®çš„è§„åˆ™æ ‡æ³¨ - ä½¿ç”¨å†³å®šæ€§è§„åˆ™
2. é«˜ç½®ä¿¡åº¦æ•°æ®è¿‡æ»¤ (â‰¥0.8)
3. è¡Œä¸š+é‡‡è´­äººåŒé‡åˆ¤å®š
4. ç®€åŒ–æ¨¡å‹ï¼Œé¿å…è¿‡æ‹Ÿåˆ
"""

import pandas as pd
import numpy as np
import re
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.utils import resample

import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)


class UltraPreciseLabeler:
    """è¶…ç²¾ç¡®æ ‡æ³¨å™¨ - ä½¿ç”¨å†³å®šæ€§è§„åˆ™ä¼˜å…ˆ"""

    def __init__(self):
        # åˆè§„èƒ½åŠ›å†³å®šæ€§æ ‡è¯†ï¼ˆæ•™è‚²+åŒ»ç–—ï¼‰
        self.compliance_decisive_purchasers = [
            'å­¦æ ¡', 'å¤§å­¦', 'å­¦é™¢', 'ä¸­å­¦', 'å°å­¦', 'å¹¼å„¿å›­', 'æ•™è‚²å±€', 'æ•™å§”',
            'åŒ»é™¢', 'å«ç”Ÿé™¢', 'ç–¾æ§', 'å«ç”Ÿå±€', 'å«å¥å§”', 'å«ç”Ÿå’Œè®¡åˆ’ç”Ÿè‚²',
            'å…¬å®‰å±€', 'æ´¾å‡ºæ‰€', 'æ³•é™¢', 'æ£€å¯Ÿé™¢', 'å¸æ³•å±€',
        ]

        self.compliance_decisive_industries = [
            'æ™®é€šé«˜ç­‰æ•™è‚²', 'ä¸­ç­‰èŒä¸šå­¦æ ¡æ•™è‚²', 'æ™®é€šå°å­¦æ•™è‚²', 'æ™®é€šåˆä¸­æ•™è‚²',
            'å­¦å‰æ•™è‚²', 'ç‰¹æ®Šæ•™è‚²', 'å…¶ä»–æ•™è‚²', 'æ•™è‚²',
            'ç»¼åˆåŒ»é™¢', 'ä¸“ç§‘åŒ»é™¢', 'ç–¾ç—…é¢„é˜²æ§åˆ¶', 'å«ç”Ÿ', 'åŒ»ç–—',
            'å«ç”Ÿå’Œç¤¾ä¼šå·¥ä½œ',
        ]

        self.compliance_decisive_keywords = [
            'æ•™å­¦è®¾å¤‡', 'æ•™å­¦ä»ªå™¨', 'å®éªŒå®¤', 'å®è®­', 'æ•™æ', 'è¯¾æœ¬', 'å›¾ä¹¦é¦†',
            'åŒ»ç–—è®¾å¤‡', 'åŒ»ç–—å™¨æ¢°', 'æ‰‹æœ¯', 'è¯Šæ–­', 'CT', 'MRI', 'Bè¶…', 'DR',
            'è¯å“', 'ç–«è‹—', 'åŒ»è¯',
            'ç›‘æ§ç³»ç»Ÿ', 'å®‰é˜²ç³»ç»Ÿ', 'æ‰§æ³•',
        ]

        # æ±²å–èƒ½åŠ›å†³å®šæ€§æ ‡è¯†
        self.extractive_decisive_purchasers = [
            'ç¨åŠ¡å±€', 'åœ°ç¨å±€', 'å›½ç¨å±€', 'è´¢æ”¿å±€', 'è´¢æ”¿å…',
            'å®¡è®¡å±€', 'å®¡è®¡å…', 'å›½åœŸå±€', 'å›½åœŸèµ„æºå±€', 'è‡ªç„¶èµ„æºå±€',
        ]

        self.extractive_decisive_industries = [
            'è´¢æ”¿', 'ç¨åŠ¡', 'é‡‘èä¸š', 'è´§å¸é‡‘èæœåŠ¡',
        ]

        self.extractive_decisive_keywords = [
            'ç¨åŠ¡', 'ç¨æ”¶', 'è´¢ç¨', 'å®¡è®¡', 'é¢„ç®—', 'å†³ç®—',
            'åœŸåœ°å‚¨å¤‡', 'åœŸåœ°å‡ºè®©', 'å¾åœ°', 'æ‹†è¿', 'èµ„äº§è¯„ä¼°', 'èµ„äº§æ¸…æŸ¥',
            'çŸ¿äº§èµ„æº', 'çŸ¿æƒ', 'äº§æƒç™»è®°', 'ä¸åŠ¨äº§ç™»è®°', 'ç¡®æƒ',
        ]

        # åè°ƒèƒ½åŠ›å†³å®šæ€§æ ‡è¯†
        self.coordination_decisive_purchasers = [
            'ä½å»ºå±€', 'ä½æˆ¿å’ŒåŸä¹¡å»ºè®¾', 'äº¤é€šå±€', 'å…¬è·¯å±€', 'å¸‚æ”¿',
            'æ°´åˆ©å±€', 'æ°´åŠ¡å±€', 'ç”µåŠ›', 'è§„åˆ’å±€',
        ]

        self.coordination_decisive_industries = [
            'åœŸæœ¨å·¥ç¨‹å»ºç­‘ä¸š', 'æˆ¿å±‹å»ºç­‘ä¸š', 'å»ºç­‘è£…é¥°ä¸š', 'å»ºç­‘å®‰è£…ä¸š',
            'é“è·¯è¿è¾“ä¸š', 'å…¬å…±è®¾æ–½ç®¡ç†ä¸š',
        ]

        self.coordination_decisive_keywords = [
            'é“è·¯å·¥ç¨‹', 'å…¬è·¯å·¥ç¨‹', 'æ¡¥æ¢å·¥ç¨‹', 'å¸‚æ”¿å·¥ç¨‹', 'æ°´åˆ©å·¥ç¨‹',
            'å»ºè®¾å·¥ç¨‹', 'æ–½å·¥', 'è£…ä¿®å·¥ç¨‹', 'ç»¿åŒ–å·¥ç¨‹',
            'ä¿¡æ¯åŒ–å»ºè®¾', 'ç”µå­æ”¿åŠ¡', 'æ™ºæ…§åŸå¸‚',
        ]

    def _check_decisive(self, text, keywords):
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…å†³å®šæ€§å…³é”®è¯"""
        if pd.isna(text):
            return False
        text_lower = str(text).lower()
        for kw in keywords:
            if kw.lower() in text_lower:
                return True
        return False

    def label_single(self, row):
        """æ ‡æ³¨å•æ¡è®°å½• - å†³å®šæ€§è§„åˆ™ä¼˜å…ˆ"""
        purchaser = str(row.get('é‡‡è´­äºº', '')) if not pd.isna(row.get('é‡‡è´­äºº')) else ''
        industry = str(row.get('æ‰€å±è¡Œä¸š', '')) if not pd.isna(row.get('æ‰€å±è¡Œä¸š')) else ''
        contract = str(row.get('åˆåŒåç§°', '')) if not pd.isna(row.get('åˆåŒåç§°')) else ''
        subject = str(row.get('ä¸»è¦æ ‡çš„åç§°', '')) if not pd.isna(row.get('ä¸»è¦æ ‡çš„åç§°')) else ''

        full_text = f"{contract} {subject}"

        # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šé‡‡è´­äººå†³å®šæ€§åˆ¤æ–­
        if self._check_decisive(purchaser, self.compliance_decisive_purchasers):
            return 'compliance', 0.95, 'é‡‡è´­äººå†³å®š:åˆè§„'
        if self._check_decisive(purchaser, self.extractive_decisive_purchasers):
            return 'extractive', 0.95, 'é‡‡è´­äººå†³å®š:æ±²å–'
        if self._check_decisive(purchaser, self.coordination_decisive_purchasers):
            return 'coordination', 0.95, 'é‡‡è´­äººå†³å®š:åè°ƒ'

        # ç¬¬äºŒä¼˜å…ˆçº§ï¼šè¡Œä¸šå†³å®šæ€§åˆ¤æ–­
        if self._check_decisive(industry, self.compliance_decisive_industries):
            return 'compliance', 0.90, 'è¡Œä¸šå†³å®š:åˆè§„'
        if self._check_decisive(industry, self.extractive_decisive_industries):
            return 'extractive', 0.90, 'è¡Œä¸šå†³å®š:æ±²å–'
        if self._check_decisive(industry, self.coordination_decisive_industries):
            return 'coordination', 0.90, 'è¡Œä¸šå†³å®š:åè°ƒ'

        # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå…³é”®è¯å†³å®šæ€§åˆ¤æ–­
        if self._check_decisive(full_text, self.compliance_decisive_keywords):
            return 'compliance', 0.85, 'å…³é”®è¯å†³å®š:åˆè§„'
        if self._check_decisive(full_text, self.extractive_decisive_keywords):
            return 'extractive', 0.85, 'å…³é”®è¯å†³å®š:æ±²å–'
        if self._check_decisive(full_text, self.coordination_decisive_keywords):
            return 'coordination', 0.85, 'å…³é”®è¯å†³å®š:åè°ƒ'

        # é»˜è®¤ï¼šåè°ƒèƒ½åŠ›ï¼ˆé€šç”¨æ”¿åºœé‡‡è´­ï¼‰
        return 'coordination', 0.3, 'é»˜è®¤:é€šç”¨é‡‡è´­'

    def label_dataframe(self, df):
        """æ ‡æ³¨æ•´ä¸ªæ•°æ®æ¡†"""
        results = df.apply(self.label_single, axis=1)
        df_labeled = df.copy()
        df_labeled['capacity_label'] = [r[0] for r in results]
        df_labeled['label_confidence'] = [r[1] for r in results]
        df_labeled['label_reason'] = [r[2] for r in results]
        return df_labeled


def load_all_data():
    """åŠ è½½æ‰€æœ‰æ•°æ®"""
    print("=" * 60)
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    print("=" * 60)

    dfs = []
    for year in ['2012', '2013', '2014']:
        try:
            df = pd.read_stata(f'{year}.dta')
            print(f"  {year}å¹´: {len(df)} æ¡")
            dfs.append(df)
        except:
            pass

    try:
        df_2015 = pd.read_excel('2015.xls')
        print(f"  2015å¹´: {len(df_2015)} æ¡")
        dfs.append(df_2015)
    except:
        pass

    df_all = pd.concat(dfs, ignore_index=True)
    print(f"\n  ğŸ“Š æ€»è®¡: {len(df_all)} æ¡")
    return df_all


def preprocess_text(text):
    if pd.isna(text):
        return ''
    text = str(text)
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def create_features(row):
    texts = []
    for col in ['åˆåŒåç§°', 'ä¸»è¦æ ‡çš„åç§°', 'æ‰€å±è¡Œä¸š', 'é‡‡è´­äºº']:
        val = row.get(col)
        if val is not None and not pd.isna(val):
            texts.append(str(val))
    return ' '.join(texts)


class HighAccuracyClassifier:
    """é«˜å‡†ç¡®åº¦åˆ†ç±»å™¨"""

    def __init__(self):
        self.label_encoder = LabelEncoder()
        self.vectorizer = None
        self.ensemble = None

    def prepare_data(self, df, test_size=0.15, confidence_threshold=0.8):
        """å‡†å¤‡æ•°æ® - åªä½¿ç”¨é«˜ç½®ä¿¡åº¦æ ·æœ¬"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        print("=" * 60)

        # ç­›é€‰é«˜ç½®ä¿¡åº¦æ ·æœ¬
        high_conf = df[df['label_confidence'] >= confidence_threshold].copy()
        print(f"  é«˜ç½®ä¿¡åº¦æ ·æœ¬ (â‰¥{confidence_threshold}): {len(high_conf)} / {len(df)} ({len(high_conf)/len(df)*100:.1f}%)")

        # åˆ›å»ºç‰¹å¾
        high_conf['combined_text'] = high_conf.apply(create_features, axis=1)
        high_conf['processed_text'] = high_conf['combined_text'].apply(preprocess_text)

        # åˆ†å‰²
        X_train_df, X_test_df = train_test_split(
            high_conf, test_size=test_size, random_state=RANDOM_STATE,
            stratify=high_conf['capacity_label']
        )

        # å¹³è¡¡è®­ç»ƒé›†
        class_counts = X_train_df['capacity_label'].value_counts()
        print(f"  åŸå§‹è®­ç»ƒé›†åˆ†å¸ƒ: {dict(class_counts)}")

        max_size = class_counts.max()
        dfs = []
        for label in class_counts.index:
            subset = X_train_df[X_train_df['capacity_label'] == label]
            if len(subset) < max_size:
                upsampled = resample(subset, replace=True, n_samples=max_size, random_state=RANDOM_STATE)
                dfs.append(upsampled)
            else:
                dfs.append(subset)
        X_train_df = pd.concat(dfs).reset_index(drop=True)

        new_counts = X_train_df['capacity_label'].value_counts()
        print(f"  å¹³è¡¡ååˆ†å¸ƒ: {dict(new_counts)}")

        # ç¼–ç 
        y_train = self.label_encoder.fit_transform(X_train_df['capacity_label'])
        y_test = self.label_encoder.transform(X_test_df['capacity_label'])

        print(f"\n  è®­ç»ƒé›†: {len(X_train_df)} æ¡")
        print(f"  æµ‹è¯•é›†: {len(X_test_df)} æ¡")

        # TF-IDF
        self.vectorizer = TfidfVectorizer(
            max_features=3000,
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.9,
            sublinear_tf=True
        )

        X_train = self.vectorizer.fit_transform(X_train_df['processed_text'])
        X_test = self.vectorizer.transform(X_test_df['processed_text'])

        print(f"  ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")

        return X_train, X_test, y_train, y_test

    def train(self, X_train, y_train):
        """è®­ç»ƒæ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸ¤– è®­ç»ƒæ¨¡å‹...")
        print("=" * 60)

        # ç®€åŒ–çš„æ¨¡å‹é…ç½®
        models = {
            'LR': LogisticRegression(max_iter=2000, C=1.5, class_weight='balanced', random_state=RANDOM_STATE),
            'SVM': SVC(kernel='rbf', C=10, gamma='scale', probability=True, class_weight='balanced', random_state=RANDOM_STATE),
            'GB': GradientBoostingClassifier(n_estimators=150, max_depth=5, learning_rate=0.1, random_state=RANDOM_STATE),
        }

        results = []
        trained_models = {}

        for name, model in models.items():
            print(f"\n  è®­ç»ƒ {name}...")
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
            model.fit(X_train, y_train)
            trained_models[name] = model
            print(f"    CVå‡†ç¡®ç‡: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
            results.append({'model': name, 'cv_acc': cv_scores.mean()})

        # é›†æˆ
        print("\n  ğŸ”— åˆ›å»ºé›†æˆæ¨¡å‹...")
        self.ensemble = VotingClassifier(
            estimators=[(k, v) for k, v in trained_models.items()],
            voting='soft',
            weights=[1.2, 1.2, 1.0]
        )
        self.ensemble.fit(X_train, y_train)

        cv_ensemble = cross_val_score(self.ensemble, X_train, y_train, cv=5, scoring='accuracy')
        print(f"    é›†æˆCVå‡†ç¡®ç‡: {cv_ensemble.mean():.4f}")

        return results

    def evaluate(self, X_test, y_test):
        """è¯„ä¼°"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ è¯„ä¼°ç»“æœ...")
        print("=" * 60)

        y_pred = self.ensemble.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='macro')

        print(f"\n  ğŸ† å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"  ğŸ† F1-Macro: {f1:.4f}")

        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred, target_names=self.label_encoder.classes_))

        print("\næ··æ·†çŸ©é˜µ:")
        cm = confusion_matrix(y_test, y_pred)
        print(pd.DataFrame(cm, index=self.label_encoder.classes_, columns=self.label_encoder.classes_))

        return accuracy, f1, y_pred


def main():
    print("\n" + "=" * 70)
    print("  æ”¿åºœé‡‡è´­åˆåŒå›½å®¶èƒ½åŠ›åˆ†ç±»å™¨ V4 - è¶…é«˜å‡†ç¡®åº¦ç‰ˆæœ¬")
    print("  ç›®æ ‡ï¼šå‡†ç¡®ç‡ > 90%")
    print("=" * 70)

    # 1. åŠ è½½æ•°æ®
    df = load_all_data()

    # 2. è¶…ç²¾ç¡®æ ‡æ³¨
    print("\n" + "=" * 60)
    print("ğŸ·ï¸  è¶…ç²¾ç¡®è§„åˆ™æ ‡æ³¨...")
    print("=" * 60)

    labeler = UltraPreciseLabeler()
    df_labeled = labeler.label_dataframe(df)

    label_counts = df_labeled['capacity_label'].value_counts()
    print("\n  æ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in label_counts.items():
        print(f"    {label}: {count} ({count/len(df_labeled)*100:.1f}%)")

    conf_dist = df_labeled['label_confidence'].value_counts().sort_index()
    print("\n  ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    for conf, count in conf_dist.items():
        print(f"    {conf}: {count}")

    # 3. è®­ç»ƒ - ä½¿ç”¨ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
    best_accuracy = 0
    best_threshold = 0.8

    for threshold in [0.85, 0.9, 0.95]:
        print(f"\n\n{'='*60}")
        print(f"  å°è¯•ç½®ä¿¡åº¦é˜ˆå€¼: {threshold}")
        print('='*60)

        classifier = HighAccuracyClassifier()
        try:
            X_train, X_test, y_train, y_test = classifier.prepare_data(df_labeled, confidence_threshold=threshold)
            classifier.train(X_train, y_train)
            accuracy, f1, y_pred = classifier.evaluate(X_test, y_test)

            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_threshold = threshold
                best_classifier = classifier
                best_results = (X_test, y_test, y_pred)
        except Exception as e:
            print(f"  é”™è¯¯: {e}")

    # 4. ç»“æœ
    print("\n" + "=" * 70)
    if best_accuracy >= 0.9:
        print(f"  ğŸ‰ æˆåŠŸï¼æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2%} (é˜ˆå€¼={best_threshold})")
    else:
        print(f"  ğŸ“ˆ æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2%} (é˜ˆå€¼={best_threshold})")
        print(f"     è·ç¦»90%ç›®æ ‡è¿˜å·®: {0.9 - best_accuracy:.2%}")
    print("=" * 70)

    # 5. ä¿å­˜
    print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    output_cols = ['å¹´ä»½', 'åˆåŒåç§°', 'ä¸»è¦æ ‡çš„åç§°', 'é‡‡è´­äºº', 'ä¾›åº”å•†',
                   'æ‰€å±è¡Œä¸š', 'åˆåŒé‡‘é¢num_ä¸‡å…ƒ', 'capacity_label',
                   'label_confidence', 'label_reason']
    df_output = df_labeled[[c for c in output_cols if c in df_labeled.columns]]
    df_output.to_csv('classified_contracts_v4.csv', index=False, encoding='utf-8-sig')
    print("  å·²ä¿å­˜: classified_contracts_v4.csv")

    # 6. ç¤ºä¾‹é¢„æµ‹
    print("\n" + "=" * 60)
    print("ğŸ”® ç¤ºä¾‹é¢„æµ‹:")
    print("=" * 60)

    test_samples = [
        {'åˆåŒåç§°': 'ç¨åŠ¡å±€ä¿¡æ¯ç³»ç»Ÿå‡çº§', 'é‡‡è´­äºº': 'å¸‚ç¨åŠ¡å±€', 'æ‰€å±è¡Œä¸š': ''},
        {'åˆåŒåç§°': 'å°å­¦æ•™å­¦è®¾å¤‡é‡‡è´­', 'é‡‡è´­äºº': 'XXå°å­¦', 'æ‰€å±è¡Œä¸š': 'æ™®é€šå°å­¦æ•™è‚²'},
        {'åˆåŒåç§°': 'é“è·¯ç»´ä¿®å·¥ç¨‹', 'é‡‡è´­äºº': 'å¸‚ä½å»ºå±€', 'æ‰€å±è¡Œä¸š': ''},
        {'åˆåŒåç§°': 'åŒ»é™¢CTè®¾å¤‡é‡‡è´­', 'é‡‡è´­äºº': 'XXåŒ»é™¢', 'æ‰€å±è¡Œä¸š': 'ç»¼åˆåŒ»é™¢'},
        {'åˆåŒåç§°': 'åŠå…¬å®¶å…·é‡‡è´­', 'é‡‡è´­äºº': 'æ”¿åºœåŠå…¬å®¤', 'æ‰€å±è¡Œä¸š': ''},
    ]

    for sample in test_samples:
        row = pd.Series(sample)
        label, conf, reason = labeler.label_single(row)
        label_cn = {'extractive': 'æ±²å–', 'coordination': 'åè°ƒ', 'compliance': 'åˆè§„'}
        print(f"  '{sample['åˆåŒåç§°']}' ({sample['é‡‡è´­äºº']}) â†’ {label_cn[label]}èƒ½åŠ› (ç½®ä¿¡åº¦:{conf})")

    return df_labeled, best_classifier, best_accuracy


if __name__ == '__main__':
    df_labeled, classifier, accuracy = main()
