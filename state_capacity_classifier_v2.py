#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¿åºœé‡‡è´­åˆåŒå›½å®¶èƒ½åŠ›åˆ†ç±»å™¨ V2
State Capacity Contract Classifier V2

æ”¹è¿›ç‰ˆæœ¬ï¼ŒåŒ…å«ï¼š
- æ›´ç²¾ç»†çš„å…³é”®è¯åŒ¹é…
- æ›´å¼ºçš„ç‰¹å¾å·¥ç¨‹
- æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆç®€å•ç¥ç»ç½‘ç»œï¼‰
- æ•°æ®å¢å¼ºå’Œç±»åˆ«å¹³è¡¡å¤„ç†

åŸºäº Berwick & Christia (2018) ã€ŠState Capacity Reduxã€‹è®ºæ–‡æ¡†æ¶
"""

import pandas as pd
import numpy as np
import re
import warnings
import json
from collections import Counter
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.utils import resample

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False

# è®¾ç½®éšæœºç§å­
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ”¹è¿›çš„åˆ†ç±»è§„åˆ™å®šä¹‰
# ============================================================================

class ImprovedStateCapacityLabeler:
    """
    æ”¹è¿›ç‰ˆæ ‡æ³¨å™¨ï¼Œä½¿ç”¨æ›´ç²¾ç»†çš„è§„åˆ™å’ŒåŠ æƒæœºåˆ¶
    """

    def __init__(self):
        # æ±²å–èƒ½åŠ›å…³é”®è¯ï¼ˆæƒé‡åŠ å¼ºï¼‰
        self.extractive_patterns = {
            # å¼ºä¿¡å·ï¼ˆæƒé‡3ï¼‰
            'strong': [
                'ç¨åŠ¡', 'ç¨æ”¶', 'è´¢ç¨', 'åœ°ç¨', 'å›½ç¨', 'è´¢æ”¿å±€', 'è´¢æ”¿å…',
                'å®¡è®¡', 'å®¡è®¡å±€', 'ä¼šè®¡', 'å‡ºçº³', 'é¢„ç®—', 'å†³ç®—',
                'èµ„äº§è¯„ä¼°', 'èµ„äº§æ¸…æŸ¥', 'å›½æœ‰èµ„äº§', 'èµ„äº§ç®¡ç†',
                'åœŸåœ°å‚¨å¤‡', 'åœŸåœ°å‡ºè®©', 'çŸ¿äº§èµ„æº', 'çŸ¿æƒ',
                'å¾æ”¶', 'å¾åœ°', 'æ‹†è¿è¡¥å¿',
            ],
            # ä¸­ç­‰ä¿¡å·ï¼ˆæƒé‡2ï¼‰
            'medium': [
                'è´¢åŠ¡', 'èµ„é‡‘', 'æ”¶è´¹', 'ç½šæ¬¾', 'ç½šæ²¡',
                'èµ„äº§', 'äº§æƒ', 'ä¸åŠ¨äº§', 'æˆ¿äº§ç™»è®°',
                'å›½åœŸ', 'åœŸåœ°', 'æµ‹ç»˜', 'åœ°ç±',
                'é“¶è¡Œ', 'é‡‘è', 'è´·æ¬¾',
            ],
            # å¼±ä¿¡å·ï¼ˆæƒé‡1ï¼‰
            'weak': [
                'è¯„ä¼°', 'é‰´å®šä»·æ ¼', 'ä»·å€¼è¯„å®š',
            ]
        }

        # åè°ƒèƒ½åŠ›å…³é”®è¯
        self.coordination_patterns = {
            'strong': [
                # åŸºç¡€è®¾æ–½å»ºè®¾
                'é“è·¯å»ºè®¾', 'å…¬è·¯å»ºè®¾', 'æ¡¥æ¢', 'éš§é“', 'å¸‚æ”¿å·¥ç¨‹',
                'æ°´åˆ©å·¥ç¨‹', 'ç”µç½‘', 'ä¾›æ°´', 'æ’æ°´', 'ç®¡ç½‘',
                'é€šä¿¡åŸºç«™', 'ç½‘ç»œå»ºè®¾', 'ä¿¡æ¯åŒ–å»ºè®¾', 'ç”µå­æ”¿åŠ¡',
                # æ”¿åºœåŠå…¬
                'æ”¿åºœé‡‡è´­', 'åŠå…¬è®¾å¤‡', 'åŠå…¬å®¶å…·', 'å…¬åŠ¡ç”¨è½¦',
            ],
            'medium': [
                'é“è·¯', 'å…¬è·¯', 'äº¤é€š', 'è¿è¾“', 'ç”µåŠ›', 'ä¾›ç”µ',
                'é€šè®¯', 'é€šä¿¡', 'ç½‘ç»œ', 'ä¿¡æ¯åŒ–', 'æ•°å­—åŒ–',
                'å»ºè®¾', 'å·¥ç¨‹', 'æ–½å·¥', 'æ”¹é€ ', 'ä¿®ç¼®', 'ç»´ä¿®',
                'è£…ä¿®', 'è£…é¥°', 'ç»¿åŒ–', 'ç¯å«',
                'åŠå…¬', 'ä¼šè®®', 'æ¡£æ¡ˆ', 'å°åˆ·', 'è½¦è¾†', 'åå‹¤',
                'è§„åˆ’', 'è®¾è®¡', 'å’¨è¯¢', 'ç›‘ç†',
            ],
            'weak': [
                'è®¾å¤‡', 'å®¶å…·', 'æ‰“å°', 'å¤å°', 'ç©ºè°ƒ', 'ç”µè„‘', 'è®¡ç®—æœº',
            ]
        }

        # åˆè§„èƒ½åŠ›å…³é”®è¯
        self.compliance_patterns = {
            'strong': [
                # æ•™è‚²æœåŠ¡
                'å­¦æ ¡', 'æ•™è‚²å±€', 'æ•™å§”', 'æ•™å­¦è®¾å¤‡', 'æ•™å­¦ä»ªå™¨',
                'å¤šåª’ä½“æ•™å­¦', 'å½•æ’­ç³»ç»Ÿ', 'å®éªŒå®¤', 'å®è®­å®¤',
                'å›¾ä¹¦é¦†', 'å›¾ä¹¦é‡‡è´­', 'æ•™æ', 'è¯¾æœ¬',
                # åŒ»ç–—å«ç”Ÿ
                'åŒ»é™¢', 'å«ç”Ÿé™¢', 'ç–¾æ§ä¸­å¿ƒ', 'åŒ»ç–—è®¾å¤‡', 'åŒ»ç–—å™¨æ¢°',
                'CT', 'MRI', 'Bè¶…', 'å½©è¶…', 'æ‰‹æœ¯', 'è¯Šæ–­',
                'è¯å“', 'åŒ»è¯', 'ç–«è‹—', 'é˜²ç–«',
                # å…¬å…±å®‰å…¨
                'å…¬å®‰å±€', 'æ´¾å‡ºæ‰€', 'è­¦åŠ¡', 'æ‰§æ³•', 'å¸æ³•å±€',
                'ç›‘æ§ç³»ç»Ÿ', 'å®‰é˜²ç³»ç»Ÿ', 'æ¶ˆé˜²', 'åº”æ€¥',
            ],
            'medium': [
                'æ•™è‚²', 'æ•™å­¦', 'åŸ¹è®­', 'å­¦ä¹ ', 'è¯¾ç¨‹',
                'åŒ»ç–—', 'å«ç”Ÿ', 'å¥åº·', 'è¯Šç–—', 'æŠ¤ç†', 'åº·å¤',
                'æ£€éªŒ', 'æ£€æµ‹', 'åŒ–éªŒ', 'å½±åƒ',
                'å®‰é˜²', 'ç›‘æ§', 'å®‰ä¿', 'ä¿å®‰',
                'ç¯ä¿', 'ç¯å¢ƒ', 'æ±¡æŸ“', 'åƒåœ¾å¤„ç†',
                'å…»è€', 'ç¦åˆ©', 'æ•‘åŠ©', 'ç¤¾åŒºæœåŠ¡',
            ],
            'weak': [
                'ä½“è‚²', 'è¿åŠ¨', 'å¥èº«', 'æ–‡åŒ–', 'è‰ºæœ¯',
            ]
        }

        # è¡Œä¸šå¼ºæ˜ å°„
        self.industry_strong_mapping = {
            # æ±²å–èƒ½åŠ›
            'è´¢æ”¿': 'extractive',
            'ç¨åŠ¡': 'extractive',
            'é‡‘èä¸š': 'extractive',

            # åˆè§„èƒ½åŠ›ï¼ˆæ•™è‚²åŒ»ç–—ï¼‰
            'æ™®é€šé«˜ç­‰æ•™è‚²': 'compliance',
            'ä¸­ç­‰èŒä¸šå­¦æ ¡æ•™è‚²': 'compliance',
            'æ™®é€šå°å­¦æ•™è‚²': 'compliance',
            'æ™®é€šåˆä¸­æ•™è‚²': 'compliance',
            'å­¦å‰æ•™è‚²': 'compliance',
            'ç‰¹æ®Šæ•™è‚²': 'compliance',
            'ç»¼åˆåŒ»é™¢': 'compliance',
            'ä¸“ç§‘åŒ»é™¢': 'compliance',
            'ç–¾ç—…é¢„é˜²æ§åˆ¶ä¸­å¿ƒ': 'compliance',
            'å«ç”Ÿå’Œç¤¾ä¼šå·¥ä½œ': 'compliance',
        }

    def _calculate_score(self, text, patterns):
        """è®¡ç®—åŠ æƒå¾—åˆ†"""
        if pd.isna(text):
            return 0
        text = str(text).lower()

        score = 0
        matched_keywords = []

        for keyword in patterns.get('strong', []):
            if keyword.lower() in text:
                score += 3
                matched_keywords.append((keyword, 3))

        for keyword in patterns.get('medium', []):
            if keyword.lower() in text:
                score += 2
                matched_keywords.append((keyword, 2))

        for keyword in patterns.get('weak', []):
            if keyword.lower() in text:
                score += 1
                matched_keywords.append((keyword, 1))

        return score, matched_keywords

    def label_single(self, contract_name, subject_name=None, industry=None, purchaser=None):
        """å¯¹å•æ¡è®°å½•è¿›è¡Œæ ‡æ³¨"""

        # åˆå¹¶æ‰€æœ‰å¯ç”¨æ–‡æœ¬
        texts = []
        if contract_name and not pd.isna(contract_name):
            texts.append(str(contract_name))
        if subject_name and not pd.isna(subject_name):
            texts.append(str(subject_name))
        if industry and not pd.isna(industry):
            texts.append(str(industry))
        if purchaser and not pd.isna(purchaser):
            texts.append(str(purchaser))

        full_text = ' '.join(texts)

        # è®¡ç®—å„ç±»åˆ«å¾—åˆ†
        ext_score, ext_keywords = self._calculate_score(full_text, self.extractive_patterns)
        coord_score, coord_keywords = self._calculate_score(full_text, self.coordination_patterns)
        comp_score, comp_keywords = self._calculate_score(full_text, self.compliance_patterns)

        # è¡Œä¸šå¼ºæ˜ å°„åŠ æˆ
        industry_label = None
        if industry and not pd.isna(industry):
            for ind_key, label in self.industry_strong_mapping.items():
                if ind_key in str(industry):
                    industry_label = label
                    if label == 'extractive':
                        ext_score += 5
                    elif label == 'coordination':
                        coord_score += 5
                    elif label == 'compliance':
                        comp_score += 5
                    break

        # é‡‡è´­äººç±»å‹åˆ¤æ–­ï¼ˆè¡¥å……è§„åˆ™ï¼‰
        if purchaser and not pd.isna(purchaser):
            purchaser_str = str(purchaser).lower()
            if any(kw in purchaser_str for kw in ['å­¦æ ¡', 'å¤§å­¦', 'å­¦é™¢', 'å°å­¦', 'ä¸­å­¦', 'å¹¼å„¿å›­', 'æ•™è‚²']):
                comp_score += 3
            elif any(kw in purchaser_str for kw in ['åŒ»é™¢', 'å«ç”Ÿé™¢', 'ç–¾æ§', 'å«ç”Ÿ']):
                comp_score += 3
            elif any(kw in purchaser_str for kw in ['ç¨åŠ¡', 'è´¢æ”¿', 'å®¡è®¡', 'å›½åœŸ']):
                ext_score += 3
            elif any(kw in purchaser_str for kw in ['ä½å»º', 'äº¤é€š', 'å…¬è·¯', 'å¸‚æ”¿']):
                coord_score += 2

        scores = {
            'extractive': ext_score,
            'coordination': coord_score,
            'compliance': comp_score
        }

        max_score = max(scores.values())
        total_score = sum(scores.values())

        if max_score == 0:
            # æ— æ˜æ˜¾ç‰¹å¾ï¼Œé»˜è®¤ä¸ºåè°ƒèƒ½åŠ›ï¼ˆé€šç”¨æ”¿åºœé‡‡è´­ï¼‰
            return 'coordination', 0.1, 'é»˜è®¤åˆ†ç±»'

        label = max(scores, key=scores.get)

        # ç½®ä¿¡åº¦è®¡ç®—ï¼ˆè€ƒè™‘åŒºåˆ†åº¦ï¼‰
        second_score = sorted(scores.values(), reverse=True)[1]
        if total_score > 0:
            confidence = (max_score - second_score + 1) / (total_score + 1)
        else:
            confidence = 0.1

        # ç”ŸæˆåŸå› è¯´æ˜
        reason = f"E:{ext_score},C:{coord_score},P:{comp_score}"

        return label, min(confidence, 1.0), reason

    def label_dataframe(self, df):
        """å¯¹æ•´ä¸ªæ•°æ®æ¡†è¿›è¡Œæ ‡æ³¨"""
        labels = []
        confidences = []
        reasons = []

        for idx, row in df.iterrows():
            label, conf, reason = self.label_single(
                row.get('åˆåŒåç§°', ''),
                row.get('ä¸»è¦æ ‡çš„åç§°', ''),
                row.get('æ‰€å±è¡Œä¸š', ''),
                row.get('é‡‡è´­äºº', '')
            )
            labels.append(label)
            confidences.append(conf)
            reasons.append(reason)

        df_labeled = df.copy()
        df_labeled['capacity_label'] = labels
        df_labeled['label_confidence'] = confidences
        df_labeled['label_reason'] = reasons

        return df_labeled


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®å¤„ç†
# ============================================================================

def load_data():
    """åŠ è½½æ•°æ®"""
    print("=" * 60)
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    print("=" * 60)

    dfs = []
    for year in ['2012', '2013', '2014']:
        df = pd.read_stata(f'{year}.dta')
        print(f"  {year}å¹´: {len(df)} æ¡è®°å½•")
        dfs.append(df)

    df_all = pd.concat(dfs, ignore_index=True)
    print(f"\n  æ€»è®¡: {len(df_all)} æ¡è®°å½•")
    return df_all


def preprocess_text(text):
    """æ–‡æœ¬é¢„å¤„ç†"""
    if pd.isna(text):
        return ''
    text = str(text)
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def create_combined_text(row):
    """åˆ›å»ºç»„åˆæ–‡æœ¬"""
    texts = []
    for col in ['åˆåŒåç§°', 'ä¸»è¦æ ‡çš„åç§°', 'æ‰€å±è¡Œä¸š', 'é‡‡è´­æ–¹å¼', 'é‡‡è´­äºº']:
        if col in row and not pd.isna(row[col]):
            texts.append(str(row[col]))
    return ' '.join(texts)


def balance_dataset(df, target_col='capacity_label', method='oversample'):
    """
    å¹³è¡¡æ•°æ®é›†
    method: 'oversample' (ä¸Šé‡‡æ ·å°‘æ•°ç±») æˆ– 'undersample' (ä¸‹é‡‡æ ·å¤šæ•°ç±»)
    """
    print("\n  æ•°æ®å¹³è¡¡å¤„ç†...")

    # è·å–å„ç±»åˆ«æ•°é‡
    class_counts = df[target_col].value_counts()
    print(f"  åŸå§‹åˆ†å¸ƒ: {dict(class_counts)}")

    if method == 'oversample':
        # ä¸Šé‡‡æ ·åˆ°æœ€å¤§ç±»çš„æ•°é‡
        max_size = class_counts.max()
        dfs = []
        for label in class_counts.index:
            df_subset = df[df[target_col] == label]
            if len(df_subset) < max_size:
                df_upsampled = resample(df_subset,
                                        replace=True,
                                        n_samples=max_size,
                                        random_state=RANDOM_STATE)
                dfs.append(df_upsampled)
            else:
                dfs.append(df_subset)

        df_balanced = pd.concat(dfs)

    elif method == 'undersample':
        min_size = class_counts.min()
        dfs = []
        for label in class_counts.index:
            df_subset = df[df[target_col] == label]
            df_downsampled = resample(df_subset,
                                      replace=False,
                                      n_samples=min_size,
                                      random_state=RANDOM_STATE)
            dfs.append(df_downsampled)

        df_balanced = pd.concat(dfs)

    new_counts = df_balanced[target_col].value_counts()
    print(f"  å¹³è¡¡ååˆ†å¸ƒ: {dict(new_counts)}")

    return df_balanced.reset_index(drop=True)


# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ†ç±»å™¨
# ============================================================================

class ImprovedStateCapacityClassifier:
    """æ”¹è¿›çš„åˆ†ç±»å™¨"""

    def __init__(self):
        self.label_encoder = LabelEncoder()
        self.vectorizer = None
        self.models = {}
        self.best_model = None
        self.best_model_name = None

    def prepare_data(self, df, test_size=0.2, balance=True):
        """å‡†å¤‡æ•°æ®"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        print("=" * 60)

        # åˆ›å»ºæ–‡æœ¬ç‰¹å¾
        df['combined_text'] = df.apply(create_combined_text, axis=1)
        df['processed_text'] = df['combined_text'].apply(preprocess_text)

        # æ•°æ®å¹³è¡¡ï¼ˆä»…å¯¹è®­ç»ƒé›†ï¼‰
        if balance:
            # å…ˆåˆ†å‰²
            X_train_df, X_test_df = train_test_split(
                df, test_size=test_size, random_state=RANDOM_STATE,
                stratify=df['capacity_label']
            )

            # å¯¹è®­ç»ƒé›†è¿›è¡Œå¹³è¡¡
            X_train_df = balance_dataset(X_train_df, 'capacity_label', 'oversample')

            y_train = self.label_encoder.fit_transform(X_train_df['capacity_label'])
            y_test = self.label_encoder.transform(X_test_df['capacity_label'])

            X_train_text = X_train_df['processed_text'].values
            X_test_text = X_test_df['processed_text'].values

        else:
            y = self.label_encoder.fit_transform(df['capacity_label'])
            X_train_text, X_test_text, y_train, y_test = train_test_split(
                df['processed_text'].values, y,
                test_size=test_size, random_state=RANDOM_STATE, stratify=y
            )

        print(f"\n  è®­ç»ƒé›†: {len(X_train_text)} æ¡")
        print(f"  æµ‹è¯•é›†: {len(X_test_text)} æ¡")
        print(f"  ç±»åˆ«: {list(self.label_encoder.classes_)}")

        # TF-IDFç‰¹å¾
        self.vectorizer = TfidfVectorizer(
            max_features=2000,
            ngram_range=(1, 3),
            min_df=1,
            max_df=0.95
        )

        X_train = self.vectorizer.fit_transform(X_train_text)
        X_test = self.vectorizer.transform(X_test_text)

        print(f"  ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")

        return X_train, X_test, y_train, y_test

    def train_models(self, X_train, y_train):
        """è®­ç»ƒæ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸ¤– è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
        print("=" * 60)

        model_configs = {
            'Logistic Regression': LogisticRegression(
                max_iter=1000, random_state=RANDOM_STATE, C=1.0, solver='lbfgs'
            ),
            'Random Forest': RandomForestClassifier(
                n_estimators=200, max_depth=15, random_state=RANDOM_STATE
            ),
            'SVM': SVC(
                kernel='rbf', C=10, gamma='scale',
                random_state=RANDOM_STATE, probability=True
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=150, max_depth=5, random_state=RANDOM_STATE
            ),
            'MLP Neural Network': MLPClassifier(
                hidden_layer_sizes=(512, 256, 128),
                max_iter=500, random_state=RANDOM_STATE,
                early_stopping=True, validation_fraction=0.1,
                activation='relu', solver='adam'
            )
        }

        results = []
        for name, model in model_configs.items():
            print(f"\n  è®­ç»ƒ {name}...")

            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')
            model.fit(X_train, y_train)
            self.models[name] = model

            result = {
                'model': name,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std()
            }
            results.append(result)
            print(f"    äº¤å‰éªŒè¯ F1: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

        best_result = max(results, key=lambda x: x['cv_mean'])
        self.best_model_name = best_result['model']
        self.best_model = self.models[self.best_model_name]

        print(f"\n  âœ… æœ€ä½³æ¨¡å‹: {self.best_model_name}")
        return results

    def evaluate(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ...")
        print("=" * 60)

        results = []
        for name, model in self.models.items():
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='macro')

            results.append({
                'model': name,
                'accuracy': accuracy,
                'f1_macro': f1
            })
            print(f"\n  {name}: å‡†ç¡®ç‡={accuracy:.4f}, F1={f1:.4f}")

        print(f"\n" + "=" * 60)
        print(f"ğŸ“‹ æœ€ä½³æ¨¡å‹ ({self.best_model_name}) è¯¦ç»†æŠ¥å‘Š:")
        print("=" * 60)

        y_pred_best = self.best_model.predict(X_test)
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred_best,
                                    target_names=self.label_encoder.classes_))

        print("\næ··æ·†çŸ©é˜µ:")
        cm = confusion_matrix(y_test, y_pred_best)
        print(pd.DataFrame(cm,
                           index=self.label_encoder.classes_,
                           columns=self.label_encoder.classes_))

        return results

    def predict(self, texts):
        """é¢„æµ‹"""
        processed = [preprocess_text(t) for t in texts]
        X = self.vectorizer.transform(processed)
        predictions = self.best_model.predict(X)
        labels = self.label_encoder.inverse_transform(predictions)

        if hasattr(self.best_model, 'predict_proba'):
            probs = self.best_model.predict_proba(X)
            return labels, probs

        return labels, None


# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šå¯è§†åŒ–
# ============================================================================

def plot_results(df_labeled, eval_results, y_test, y_pred, label_encoder):
    """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""

    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    print("=" * 60)

    fig, axes = plt.subplots(2, 2, figsize=(14, 12))

    # 1. æ ‡ç­¾åˆ†å¸ƒ
    label_counts = df_labeled['capacity_label'].value_counts()
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    axes[0, 0].bar(label_counts.index, label_counts.values, color=colors)
    axes[0, 0].set_title('State Capacity Label Distribution', fontsize=12)
    axes[0, 0].set_xlabel('Capacity Type')
    axes[0, 0].set_ylabel('Count')
    for i, v in enumerate(label_counts.values):
        axes[0, 0].text(i, v + 5, str(v), ha='center')

    # 2. æ¨¡å‹å¯¹æ¯”
    df_results = pd.DataFrame(eval_results)
    x = np.arange(len(df_results))
    width = 0.35
    axes[0, 1].bar(x - width/2, df_results['accuracy'], width, label='Accuracy', color='#4ECDC4')
    axes[0, 1].bar(x + width/2, df_results['f1_macro'], width, label='F1-Macro', color='#FF6B6B')
    axes[0, 1].set_xlabel('Model')
    axes[0, 1].set_ylabel('Score')
    axes[0, 1].set_title('Model Performance Comparison', fontsize=12)
    axes[0, 1].set_xticks(x)
    axes[0, 1].set_xticklabels(df_results['model'], rotation=45, ha='right')
    axes[0, 1].legend()
    axes[0, 1].set_ylim(0, 1.0)

    # 3. æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    im = axes[1, 0].imshow(cm, interpolation='nearest', cmap='Blues')
    axes[1, 0].figure.colorbar(im, ax=axes[1, 0])
    labels = label_encoder.classes_
    axes[1, 0].set(xticks=np.arange(cm.shape[1]),
                   yticks=np.arange(cm.shape[0]),
                   xticklabels=labels, yticklabels=labels,
                   title='Confusion Matrix',
                   ylabel='True Label',
                   xlabel='Predicted Label')
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            axes[1, 0].text(j, i, format(cm[i, j], 'd'),
                           ha="center", va="center",
                           color="white" if cm[i, j] > thresh else "black")

    # 4. ç½®ä¿¡åº¦åˆ†å¸ƒ
    for label in df_labeled['capacity_label'].unique():
        subset = df_labeled[df_labeled['capacity_label'] == label]
        axes[1, 1].hist(subset['label_confidence'], bins=15, alpha=0.6, label=label)
    axes[1, 1].set_title('Label Confidence Distribution', fontsize=12)
    axes[1, 1].set_xlabel('Confidence')
    axes[1, 1].set_ylabel('Count')
    axes[1, 1].legend()

    plt.tight_layout()
    plt.savefig('analysis_results_v2.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("  å›¾è¡¨å·²ä¿å­˜: analysis_results_v2.png")


# ============================================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šä¸»ç¨‹åº
# ============================================================================

def main():
    """ä¸»ç¨‹åº"""
    print("\n" + "=" * 70)
    print("  æ”¿åºœé‡‡è´­åˆåŒå›½å®¶èƒ½åŠ›åˆ†ç±»å™¨ V2")
    print("  åŸºäº Berwick & Christia (2018) ã€ŠState Capacity Reduxã€‹")
    print("=" * 70)

    # 1. åŠ è½½æ•°æ®
    df = load_data()

    # 2. æ”¹è¿›çš„è§„åˆ™æ ‡æ³¨
    print("\n" + "=" * 60)
    print("ğŸ·ï¸  åŸºäºæ”¹è¿›è§„åˆ™çš„åˆå§‹æ ‡æ³¨...")
    print("=" * 60)

    labeler = ImprovedStateCapacityLabeler()
    df_labeled = labeler.label_dataframe(df)

    label_counts = df_labeled['capacity_label'].value_counts()
    print("\n  æ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in label_counts.items():
        pct = count / len(df_labeled) * 100
        print(f"    {label}: {count} ({pct:.1f}%)")

    # 3. è®­ç»ƒåˆ†ç±»å™¨
    classifier = ImprovedStateCapacityClassifier()
    X_train, X_test, y_train, y_test = classifier.prepare_data(df_labeled, balance=True)
    cv_results = classifier.train_models(X_train, y_train)
    eval_results = classifier.evaluate(X_test, y_test)

    # 4. å¯è§†åŒ–
    y_pred = classifier.best_model.predict(X_test)
    plot_results(df_labeled, eval_results, y_test, y_pred, classifier.label_encoder)

    # 5. ç¤ºä¾‹é¢„æµ‹
    print("\n" + "=" * 60)
    print("ğŸ”® ç¤ºä¾‹é¢„æµ‹:")
    print("=" * 60)

    test_texts = [
        "ç¨åŠ¡ç³»ç»Ÿå‡çº§æ”¹é€ é¡¹ç›® ç¨åŠ¡å±€",
        "XXå°å­¦æ•™å­¦è®¾å¤‡é‡‡è´­ æ•™è‚²å±€",
        "å¸‚æ”¿é“è·¯ç»´ä¿®å·¥ç¨‹ ä½å»ºå±€",
        "åŒ»é™¢CTè®¾å¤‡é‡‡è´­ ç»¼åˆåŒ»é™¢",
        "è´¢æ”¿é¢„ç®—ç®¡ç†ç³»ç»Ÿ è´¢æ”¿å±€",
        "åŠå…¬å®¶å…·é‡‡è´­ æ”¿åºœåŠå…¬å®¤",
        "ç–«è‹—é‡‡è´­é¡¹ç›® ç–¾æ§ä¸­å¿ƒ",
        "åœŸåœ°ç¡®æƒç™»è®°ç³»ç»Ÿ å›½åœŸå±€",
    ]

    labels, probs = classifier.predict(test_texts)

    label_names_cn = {
        'extractive': 'æ±²å–èƒ½åŠ› (Extractive)',
        'coordination': 'åè°ƒèƒ½åŠ› (Coordination)',
        'compliance': 'åˆè§„èƒ½åŠ› (Compliance)'
    }

    for text, label in zip(test_texts, labels):
        print(f"  '{text[:30]}...' â†’ {label_names_cn.get(label, label)}")

    # 6. ä¿å­˜ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    print("=" * 60)

    output_cols = ['å¹´ä»½', 'åˆåŒåç§°', 'ä¸»è¦æ ‡çš„åç§°', 'é‡‡è´­äºº', 'ä¾›åº”å•†',
                   'æ‰€å±è¡Œä¸š', 'åˆåŒé‡‘é¢num_ä¸‡å…ƒ', 'capacity_label',
                   'label_confidence', 'label_reason']
    df_output = df_labeled[[c for c in output_cols if c in df_labeled.columns]]
    df_output.to_csv('classified_contracts_v2.csv', index=False, encoding='utf-8-sig')
    print("  åˆ†ç±»ç»“æœå·²ä¿å­˜: classified_contracts_v2.csv")

    pd.DataFrame(eval_results).to_csv('model_evaluation_v2.csv', index=False)
    print("  æ¨¡å‹è¯„ä¼°å·²ä¿å­˜: model_evaluation_v2.csv")

    # 7. ç”Ÿæˆåˆ†ç±»æ‘˜è¦
    print("\n" + "=" * 70)
    print("ğŸ“Š åˆ†ç±»ç»“æœæ‘˜è¦")
    print("=" * 70)

    summary = df_labeled.groupby('capacity_label').agg({
        'åˆåŒé‡‘é¢num_ä¸‡å…ƒ': ['count', 'sum', 'mean'],
    }).round(2)
    summary.columns = ['åˆåŒæ•°é‡', 'é‡‘é¢æ€»è®¡(ä¸‡å…ƒ)', 'å¹³å‡é‡‘é¢(ä¸‡å…ƒ)']
    print(summary)

    print("\n" + "=" * 70)
    print("  âœ… åˆ†ç±»å®Œæˆ!")
    print("=" * 70)

    return df_labeled, classifier


if __name__ == '__main__':
    df_labeled, classifier = main()
